# -*- coding: utf-8 -*-
"""no-over.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hjziR2aUZTdP1OTdsTAfAm_7gSdiTRUe

# Final Project

## Data Processing
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import os
import torch
import torch.nn as nn
import torchvision
from torchvision import models,transforms,datasets # import datasets
from torch.utils.data import DataLoader, WeightedRandomSampler
import time
# %matplotlib inline

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print('Using gpu: %s ' % torch.cuda.is_available())

from zipfile import ZipFile
file_name = "Alz.zip"

with ZipFile("Alz.zip", 'r') as zip:
  zip.extractall()
  print('Done')

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

# Define transformations
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
image_transforms = transforms.Compose([
    transforms.CenterCrop(176),
    transforms.ToTensor(),
    normalize
])

# Load datasets
full_train_dataset = datasets.ImageFolder(root='/content/Alzheimer_s Dataset', transform=image_transforms)
test_dataset = datasets.ImageFolder(root='/content/Alzheimer_s Dataset', transform=image_transforms)

# Splitting the full training dataset into training and validation sets
train_size = int(0.8 * len(full_train_dataset))
validation_size = len(full_train_dataset) - train_size
train_dataset, validation_dataset = random_split(full_train_dataset, [train_size, validation_size])

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
valid_loader = DataLoader(validation_dataset, batch_size=128, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

classes = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']

def imshow(img):
    img = (img - np.min(img)) / (np.max(img) - np.min(img))
    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image
# obtain one batch of training images
dataiter = iter(train_loader)
images, labels = next(dataiter)
images = images.numpy() # convert images to numpy for display
images.shape

# plot the images in the batch, along with the corresponding labels
fig = plt.figure(figsize=(25, 4))
# display 20 images
for idx in np.arange(20):
    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
    imshow(images[idx])
    ax.set_title(classes[labels[idx]])

"""## Modeling

### Our Model
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        # Assuming the input shape will be (None, None, None, 3) i.e., (batch_size, height, width, channels)
        self.conv2d_10 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        self.conv2d_11 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)
        self.max_pooling2d_5 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Sequential layers
        self.sequential_7 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.sequential_8 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.sequential_9 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        # Dropout layers
        self.dropout_5 = nn.Dropout(0.5)
        self.dropout_6 = nn.Dropout(0.5)

        # Flatten layer
        self.flatten = nn.Flatten()

        # More Sequential layers
        self.sequential_11 = nn.Sequential(
            nn.Linear(in_features=15488, out_features=512),
            nn.ReLU()
        )
        self.sequential_12 = nn.Sequential(
            nn.Linear(in_features=512, out_features=128),
            nn.ReLU()
        )
        self.sequential_13 = nn.Sequential(
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU()
        )

        # Dense layer
        self.dense_7 = nn.Linear(in_features=64, out_features=4)

    def forward(self, x):
        x = self.conv2d_10(x)
        x = self.conv2d_11(x)
        x = self.max_pooling2d_5(x)
        x = self.sequential_7(x)
        x = self.sequential_8(x)
        x = self.sequential_9(x)
        x = self.dropout_5(x)
        x = x.view(x.size(0), -1)  # Flatten layer
        x = self.sequential_11(x)
        x = self.sequential_12(x)
        x = self.sequential_13(x)
        x = self.dropout_6(x)
        x = self.dense_7(x)
        return x

model = CNNModel()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

NUM_EPOCHS = 20

for epoch in range(NUM_EPOCHS):
    model.train()
    training_loss = 0.0
    num_batches = 0

    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        training_loss += loss.item()
        num_batches += 1

    average_training_loss = training_loss / num_batches

    # Validation loop
    model.eval()
    total = 0
    correct = 0
    with torch.no_grad():
        for images, labels in valid_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    validation_accuracy = 100 * correct / total
    print(f'Epoch {epoch+1}, Training Loss: {average_training_loss:.4f}, Validation Accuracy: {validation_accuracy}%')

model.eval()

with torch.no_grad():
    correct = 0
    total = 0

    for images, labels in test_loader:

        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f'Accuracy on test set: {accuracy}%')

torch.save(model, 'alz_model.pth')
from google.colab import files
files.download('alz_model.pth')

"""### LeNet

### VGG16
"""

model_vgg = models.vgg16(weights='DEFAULT')
for param in model_vgg.parameters():
    param.requires_grad = False

model_vgg.classifier[6] = nn.Linear(4096, 4)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_vgg = model_vgg.to(device)

criterion = nn.CrossEntropyLoss()
lr = 0.001
# here we only update the parameters of the linear layer that we added
optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)

def train_model(model, dataloader, size, epochs, optimizer):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        running_corrects = 0

        for inputs, classes in dataloader:
            inputs = inputs.to(device)
            classes = classes.to(device)

            # Forward pass
            outputs = model(inputs)

            # Compute loss
            loss = criterion(outputs, classes)

            # Zero out gradients
            optimizer.zero_grad()

            # Backward pass and optimize
            loss.backward()
            optimizer.step()

            # Statistics
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == classes)

        epoch_loss = running_loss / size
        epoch_acc = running_corrects.double() / size

        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

"""## Discussion

### Confusion Matrix
"""

import torch
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Your existing code
model.eval()

y_pred = []
y_true = []

with torch.no_grad():
    correct = 0
    total = 0

    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)

        # Append the labels to our lists
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Accuracy on test set: {accuracy}%')

# Now calculate the confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)

# Optionally, plot the confusion matrix
sns.heatmap(cm, annot=True, fmt="d")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()